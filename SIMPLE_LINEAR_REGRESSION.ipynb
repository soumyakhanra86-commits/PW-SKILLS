{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q.1/ What is Simple Linear Regression ?  \n",
        "ANS:- Simple linear regression is a statistical methode used to model the linear relationship between one independent variable and one dependent variable by fitting a straight line."
      ],
      "metadata": {
        "id": "yokb5eUHjfbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2/ What are the key assumptions of Simple Linear Regression ?  \n",
        "ANS:- Linearity: Y and X have a linear relationship.  \n",
        "Independence: Observations are independent.  \n",
        "Homoscedasticity: Constant variance of errors.\n",
        "Normality of errors: Residuals follow a normal distribution.\n",
        "No significant outliers ."
      ],
      "metadata": {
        "id": "8x9AHfAXmKlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3/ What does the coefficient m represent in the equation Y=mX+c ?  \n",
        "ANS:- The coefficient m(the slope) represents the average change in the dependent variable (Y) for every one-unit increase in the independent variable (X), while holding all other variables constant (although in SLR, there is only one X). It indicates the direction (positive or negative) and steepness of the linear relationship."
      ],
      "metadata": {
        "id": "jykvS8pgnKjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4/ What does the intercept c represent in the equation Y=mX+c ?  \n",
        "ANS:-The interceprt c represents the  predicted mean value of the dependent variable (Y) when the independent variable (X) is equal to zero. It serves as the baseline for the regression line."
      ],
      "metadata": {
        "id": "WbO2JK3VoV6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5/ How do we calculate the slope m in Simple Linear Regression ?\n",
        "ANS:-The slope $m$ (often denoted as $\\beta_1$ or $b_1$) in Simple Linear Regression is calculated using the Ordinary Least Squares (OLS) method. The formula utilizes the sample covariance of $X$ and $Y$ and the sample variance of $X$:$$m = \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n} (X_i - \\bar{X})^2} = \\frac{Cov(X, Y)}{Var(X)}$$"
      ],
      "metadata": {
        "id": "KmickFbSv9TB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6/ What is the purpose of the least squares method in Simple Linear Regression ?  \n",
        "ANS:-The purpose of least5 square methode is to find the line that minimizes the sum of squared errors,giving the best-fit line."
      ],
      "metadata": {
        "id": "ORMLkyabwa2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7/ How is the coefficient of determination (R²) interpreted in Simple Linear Regression ?  \n",
        "ANS:-R² shows the percentage of variation in Y that is explained by X."
      ],
      "metadata": {
        "id": "L1xLMRJrxGkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8/ What is Multiple Linear Regression ?  \n",
        "ANS:- A regression method where multiple independent variables (X1, X2, X3, …) predict a single dependent variable Y."
      ],
      "metadata": {
        "id": "T-Y1whOrxwpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9/ What is the main difference between Simple and Multiple Linear Regression ?  \n",
        "ANS:- The main difference lies in the number of independent variables:Simple Linear Regression (SLR) uses only one independent variable (X).Multiple Linear Regression (MLR) uses two or more independent variables ( x1,x2,x3...)."
      ],
      "metadata": {
        "id": "BX_Z1z0A0FAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10/ What are the key assumptions of Multiple Linear Regression ?  \n",
        "ans:-The key assumptions of Multiple Linear Regression are:-\n",
        "Linearity between Y and each X.\n",
        "\n",
        "Independence of observations.  \n",
        "Homoscedasticity of residuals.  \n",
        "Normal distribution of residuals.  \n",
        "No multicollinearity among predictors.  \n",
        "No autocorrelation"
      ],
      "metadata": {
        "id": "Ocab1IY51LVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.11/ What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model ?  \n",
        "ANS:-Heteroscedasticity is the violation of the homoscedasticity assumption, meaning the variance of the residuals is not constant across all levels of the independent variable ."
      ],
      "metadata": {
        "id": "WszqvRh83asU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.12/How can you improve a Multiple Linear Regression model with high multicollinearity ?  \n",
        "\n",
        "ANS:-Remove correlated variables.  \n",
        "Combine variables (e.g., PCA).  \n",
        "Use regularization (Ridge, Lasso).  \n",
        "Increase sample size.  \n",
        "Create domain-based variable selection."
      ],
      "metadata": {
        "id": "sbb7F8gE3kg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.13/ What are some common techniques for transforming categorical variables for use in regression models ?  \n",
        "ANS:-One-hot encoding (Dummy variables)  \n",
        "Label encoding  \n",
        "Ordinal encoding  \n",
        "Binary encoding  \n",
        "Target encoding"
      ],
      "metadata": {
        "id": "TuhcQHdn77pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.14/ What is the role of interaction terms in Multiple Linear Regression ?  \n",
        "ANS:-Interaction terms (e.g., X1×X2) capture how the effect of one variable changes depending on another variable ."
      ],
      "metadata": {
        "id": "S5PzDCTy88QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.15/ How can the interpretation of intercept differ between Simple and Multiple Linear Regression ?  \n",
        "ANS:-SLR Intercept (c): Represents the predicted Y when the single independent variable (X) is zero.MLR Intercept ($\\beta_0$): Represents the predicted $Y$ when all independent variables ($X_1, X_2, \\ldots, X_k$) are simultaneously zero.The MLR interpretation is often more abstract and potentially meaningless if the zero value is outside the practical range for many predictors in the model (e.g., predicting salary when experience, age, and education are all zero)."
      ],
      "metadata": {
        "id": "Ar49kQEW7ZdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.16/ What is the significance of the slope in regression analysis, and how does it affect predictions ?  \n",
        "ANS:-The slope shows how much the dependent variable Y changes for a one-unit change in X.\n",
        "A larger slope means a stronger effect of X on Y, and it directly influences predictions by increasing or decreasing the predicted value of Y."
      ],
      "metadata": {
        "id": "iYTzDRvM-XIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.17/How does the intercept in a regression model provide context for the relationship between variables ?  \n",
        "ANS:-The intercept is the predicted value of Y when all X = 0.\n",
        "It provides a baseline reference point that helps you understand where the regression line starts."
      ],
      "metadata": {
        "id": "gddU56-ePq2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.18/ What are the limitations of using R² as a sole measure of model performance ?  \n",
        "\n",
        "ANS:-R² only tells how much variance in Y is explained by the model — it does not tell:  \n",
        "whether the model is appropriate  \n",
        "whether coefficients are significant  \n",
        "if overfitting exists  \n",
        "if assumptions are violated"
      ],
      "metadata": {
        "id": "-Jzux71TQhuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.19/ How would you interpret a large standard error for a regression coefficient ?  \n",
        "ANS:- A large standard error for a regression coefficient indicates that the estimated coefficient is imprecise and unreliable. It means there is high uncertainty around the estimated value, and the coefficient may vary substantially across different samples. As a result, the coefficient is less likely to be statistically significant because a large standard error leads to a smaller t-statistic and a higher p-value. This also produces a wide confidence interval, suggesting that the true effect of the predictor on the response variable is not clearly determined. Large standard errors commonly arise due to small sample sizes, multicollinearity among predictors, or high variability in the data."
      ],
      "metadata": {
        "id": "EIuyWFDeXoV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.20/ How can heteroscedasticity be identified in residual plots, and why is it important to address it ?  \n",
        "ANS:- Heteroscedasticity can be identified in residual plots when the residuals do not have a constant spread. Instead of being randomly scattered around zero, they may form patterns such as a funnel or cone shape, where the variance increases or decreases with fitted values.\n",
        "It is important to address heteroscedasticity because it violates the constant variance assumption of linear regression. While the coefficient estimates may still be unbiased, the standard errors become unreliable, leading to incorrect p-values and confidence intervals and potentially wrong conclusions."
      ],
      "metadata": {
        "id": "US7eATElbGB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.21/ What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R² ?  \n",
        "ANS:-A high R² but low adjusted R² indicates that the model includes unnecessary or irrelevant predictors. While R² increases with more variables, adjusted R² penalizes them, so a low adjusted R² suggests overfitting and poor generalization"
      ],
      "metadata": {
        "id": "3Bqjr49Gb4Xr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.22/ Why is it important to scale variables in Multiple Linear Regression ?  \n",
        "ANS:- It is important to scale variables in Multiple Linear Regression because predictors may be measured on different scales. Scaling ensures that no variable dominates the model due to its large magnitude, helps make coefficients more comparable, and improves numerical stability and convergence, especially when using regularization methods or gradient-based algorithms ."
      ],
      "metadata": {
        "id": "R-sr4h6YdDY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.23/ What is polynomial regression ?  \n",
        "ANS:- Polynomial regression is a type of regression in which the relationship between the independent variable and the dependent variable is modeled as a polynomial function of the independent variable. It is used when the relationship is non-linear, and it extends linear regression by adding polynomial terms while remaining linear in the coefficients ."
      ],
      "metadata": {
        "id": "iJnHOQOHdxH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.24/ How does polynomial regression differ from linear regression ?  \n",
        "ANS:- Polynomial regression differs from linear regression in that linear regression models a straight-line relationship between the independent and dependent variables, while polynomial regression models a curved, non-linear relationship by including higher-degree terms However, polynomial regression is still linear in its coefficients ."
      ],
      "metadata": {
        "id": "ed-Ka8d9fec8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.25/ When is polynomial regression used ?  \n",
        "ANS:- Polynomial regression is used when there is a non-linear relationship between the independent and dependent variables and a linear model cannot capture the pattern properly. It is especially useful when the data shows a curved trend ."
      ],
      "metadata": {
        "id": "fbr56rczgSzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "We2j6EKwg9Km"
      }
    }
  ]
}