{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **THEORITICAL-QUESTION**"
      ],
      "metadata": {
        "id": "65i_UcSGZmnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q.1/ Can we use Bagging for regression problems ?  \n",
        " ANS:-Yes we can use Bagging for regression problems . Bagging works for regression by averaging the numerical predictions of all individual models to produce a final output."
      ],
      "metadata": {
        "id": "czYCN0LkdLNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2/ What is the difference between multiple model training and single model training ?  \n",
        "ANS:-Single model training uses one algorithm, while multiple model training combines predictions from many models to improve performance and stability."
      ],
      "metadata": {
        "id": "PB_am7Vwe2XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3/ Explain the concept of feature randomness in Random Forest ?  \n",
        "ANS:-In a standard Decision Tree, the algorithm searches all features to find the best split. In a Random Forest, at each node split, the algorithm only considers a random subset of features. This \"decorrelates\" the trees, ensuring they don't all pick the same dominant feature, which increases diversity ."
      ],
      "metadata": {
        "id": "5aEiLoo_hl5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4/ What is OOB (Out-of-Bag) Score ?\n",
        "ANS:-OOB score evaluates model performance using samples not selected during bootstrap sampling, without a separate validation set."
      ],
      "metadata": {
        "id": "-KD0KBo-izEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5/ How can you measure the importance of features in a Random Forest model ?  \n",
        "ANS:-y calculating how much each feature reduces impurity (Gini/entropy) or using permutation importance."
      ],
      "metadata": {
        "id": "1qOewq1HjJ3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6/ Explain the working principle of a Bagging Classifier ?  \n",
        "ANS:- It works in three steps:  \n",
        "\n",
        "Bootstrapping: Create multiple random subsets of the training data with replacement.  \n",
        "Parallel Training: Train a classifier (like a Decision Tree) on each subset independently.  \n",
        "Aggregating: Combine predictions using Majority Voting."
      ],
      "metadata": {
        "id": "pGFAf6O0jdTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7/ How do you evaluate a Bagging Classifier’s performance ?   \n",
        "ANS:- Using accuracy, precision, recall, F1-score, confusion matrix, or OOB score."
      ],
      "metadata": {
        "id": "ask89lSdj5b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8/  How does a Bagging Regressor works ?  \n",
        "ANS:- The process is identical to the Bagging Classifier, but instead of majority voting, the final prediction is the average (mean) of all the individual regression models' outputs."
      ],
      "metadata": {
        "id": "VqH9EgAQkPif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9/ What is the main advantage of ensemble techniques ?  \n",
        "ANS:- They improve accuracy and reduce overfitting by combining multiple models."
      ],
      "metadata": {
        "id": "foXAnB2UkmFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10/ What is the main challenge of ensemble methods ?  \n",
        "ANS:- Complexity: They are harder to interpret than a single model .  \n",
        "Computation: They require more memory and processing power to train and store multiple models."
      ],
      "metadata": {
        "id": "q_87Hu82lBbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.11/ Explain the key idea behind ensemble techniques ?  \n",
        "ANS:- The key idea behind ensemble techniques is to combine multiple models to build a stronger and more accurate model than any single model alone. Instead of relying on one predictor, ensemble methods aggregate the predictions of several base models to improve overall performance ."
      ],
      "metadata": {
        "id": "MQdS9GYMUvEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.12/ What is a Random Forest Classifier ?  \n",
        "ANS:-A Random Forest Classifier is one of the most popular and powerful machine learning algorithms. It is a specific type of Bagging ensemble that uses a \"forest\" of many individual Decision Trees to make a final classification ."
      ],
      "metadata": {
        "id": "WJGYNeMJV8KX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.13/ What are the main types of ensemble techniques ?  \n",
        "ANS:- Bagging, Boosting, and Stacking"
      ],
      "metadata": {
        "id": "lCyJseY2WcjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.14/ What is ensemble learning in machine learning ?  \n",
        "ANS:-Its an technique where multiple models are combined to improve predictive performance ."
      ],
      "metadata": {
        "id": "uhNNxlOIXBei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.15/  When should we avoid using ensemble methods ?  \n",
        "ANS:- When data is very small, interpretability is critical, or computational resources are limited ."
      ],
      "metadata": {
        "id": "4Sg5-_8VX-mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.16/ How does Bagging help in reducing overfitting ?  \n",
        "ANS:-Bagging is a powerfull ensembel methode to desinged to improve the stability and accuracy of machine learning algorithms. Its primary way of reducing overfitting is by reducing variance—the tendency of a model to be overly sensitive to the specific noise in its training data ."
      ],
      "metadata": {
        "id": "HdwyuojAnXkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.17/ Why is Random Forest better than a single Decision Tree ?  \n",
        "ANS:- While a single Decision Tree is like a single advisor giving you an answer, a Random Forest is like a committee of experts debating to reach a final consensus.\n",
        "Random Forest is generally superior because it addresses the single biggest flaw of Decision Trees: instability and overfitting ."
      ],
      "metadata": {
        "id": "mWmV4n_bpQl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.18/ What is the role of bootstrap sampling in Bagging ?  \n",
        "ANS:-Bootstrap sampling creates multiple different training datasets by randomly sampling the original data with replacement. Each dataset is used to train a separate model, which introduces diversity among models. This diversity helps reduce variance and overfitting, making the final aggregated prediction more stable and accurate."
      ],
      "metadata": {
        "id": "s2vtTAFVviOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.19/ What are some real-world applications of ensemble techniques ?   \n",
        "ANS:-Fraud detection   \n",
        "Medical diagnosis   \n",
        "Stock market prediction  \n",
        "Recommendation systems"
      ],
      "metadata": {
        "id": "0e6VSFJuzprx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.20/ What is the difference between Bagging and Boosting ?  \n",
        "ANS:- Bagging reduces variance by training models independently, while Boosting reduces bias by training models sequentially and focusing on errors."
      ],
      "metadata": {
        "id": "4DRw5bEh13Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRACTICAL-QUESTION**"
      ],
      "metadata": {
        "id": "iLOuoFGk6zgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.21/ Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy ?"
      ],
      "metadata": {
        "id": "TbfQ7i4Z7OLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4FDwL9i1zyM",
        "outputId": "27734ea8-c4d9-4f2e-8606-37343907bdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=dt,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_model.fit(X_train, y_train)\n",
        "y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.22/ Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE) ?"
      ],
      "metadata": {
        "id": "SR6Wd_UW9YQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=dt,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pjf4Z079ey8",
        "outputId": "bb558a31-bba0-4d1c-b3e5-c223fd702106"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.2568358813508342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.23/ Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores ?"
      ],
      "metadata": {
        "id": "-qw1sE45ClMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': data.feature_names,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcbSIszAFsQm",
        "outputId": "260e6e88-3996-4633-8898-119ad5e24bb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9707602339181286\n",
            "                    Feature  Importance\n",
            "7       mean concave points    0.141934\n",
            "27     worst concave points    0.127136\n",
            "23               worst area    0.118217\n",
            "6            mean concavity    0.080557\n",
            "20             worst radius    0.077975\n",
            "22          worst perimeter    0.074292\n",
            "2            mean perimeter    0.060092\n",
            "3                 mean area    0.053810\n",
            "26          worst concavity    0.041080\n",
            "0               mean radius    0.032312\n",
            "13               area error    0.029538\n",
            "21            worst texture    0.018786\n",
            "25        worst compactness    0.017539\n",
            "10             radius error    0.016435\n",
            "28           worst symmetry    0.012929\n",
            "12          perimeter error    0.011770\n",
            "24         worst smoothness    0.011769\n",
            "1              mean texture    0.011064\n",
            "5          mean compactness    0.009216\n",
            "19  fractal dimension error    0.007135\n",
            "29  worst fractal dimension    0.006924\n",
            "4           mean smoothness    0.006223\n",
            "14         smoothness error    0.005881\n",
            "16          concavity error    0.005816\n",
            "15        compactness error    0.004596\n",
            "18           symmetry error    0.004001\n",
            "17     concave points error    0.003382\n",
            "8             mean symmetry    0.003278\n",
            "11            texture error    0.003172\n",
            "9    mean fractal dimension    0.003140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.24/ Train a Random Forest Regressor and compare its performance with a single Decision Tree ?"
      ],
      "metadata": {
        "id": "_ICF2vocKhub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf= RandomForestRegressor(n_estimators=100,random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "print(\"Random Forest Regressor MSE:\", mse_rf)\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "print(\"Decision Tree Regressor MSE:\", mse_dt)\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "if mse_rf < mse_dt:\n",
        "    print(\"Random Forest Regressor performed better (lower MSE).\")\n",
        "else:\n",
        "    print(\"Decision Tree Regressor performed better (lower MSE).\")"
      ],
      "metadata": {
        "id": "TnV0RfL2Kpko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce99c57-b69c-492c-b6dc-f63d52bfeb86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor MSE: 0.25650512920799395\n",
            "Decision Tree Regressor MSE: 0.5280096503174904\n",
            "\n",
            "Comparison:\n",
            "Random Forest Regressor performed better (lower MSE).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.25/ Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier ?"
      ],
      "metadata": {
        "id": "6CC0mZeGLU-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "rf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "\n",
        "rf_oob.fit(X_train, y_train)\n",
        "\n",
        "print(\"Out-of-Bag (OOB) Score:\", rf_oob.oob_score_)"
      ],
      "metadata": {
        "id": "alsJK74WLbwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9badc255-cf21-4ebb-92a5-266c883460b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag (OOB) Score: 0.9428571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.26/ Train a Bagging Classifier using SVM as a base estimator and print accuracy ?"
      ],
      "metadata": {
        "id": "2WxfMuW1BB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "df1=load_iris()\n",
        "x=df1.data\n",
        "y=df1.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
        "svm=SVC()\n",
        "bagging_model=BaggingClassifier(estimator=svm,n_estimators=100,random_state=42)\n",
        "bagging_model.fit(x_train,y_train)\n",
        "y_pred=bagging_model.predict(x_test)\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy:\",accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwuctw0LBBuv",
        "outputId": "debf449e-a247-4a0f-aff9-60c24cd02a34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.27/Train a Random Forest Classifier with different numbers of trees and compare accuracy ?"
      ],
      "metadata": {
        "id": "1V6OxXXkE_gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "trees = [10, 50, 100, 200]\n",
        "for n in trees:\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n,\n",
        "        random_state=42\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Number of Trees: {n}, Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF8ZZ_1MFGbw",
        "outputId": "ba70561c-d13b-4d91-bdc6-05d500d92ebb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Trees: 10, Accuracy: 0.9649\n",
            "Number of Trees: 50, Accuracy: 0.9708\n",
            "Number of Trees: 100, Accuracy: 0.9708\n",
            "Number of Trees: 200, Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.28/ Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score ?"
      ],
      "metadata": {
        "id": "hAqgkXwhHwtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "dtu=load_iris()\n",
        "x=dtu.data\n",
        "y=dtu.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
        "lr1=LogisticRegression(max_iter=1000)\n",
        "bg_classifier=BaggingClassifier(estimator=lr1,n_estimators=100,random_state=42)\n",
        "bg_classifier.fit(x_train,y_train)\n",
        "y_pred_proba = bg_classifier.predict_proba(x_test)\n",
        "auroc=roc_auc_score(y_test,y_pred_proba, multi_class='ovr', average='weighted')\n",
        "print(\"AUC Score:\",auroc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJkpgPbXK6WT",
        "outputId": "d2dcbaa3-23b4-4d4f-842a-108ff85c6342"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.29/ Train a Random Forest Regressor and analyze feature importance scores ?"
      ],
      "metadata": {
        "id": "l1kS1isVLFQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "importances = rf.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp5Y_U9ZLld0",
        "outputId": "9fd9d0bd-c587-4124-8604-92f32503c7c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Feature  Importance\n",
            "0      MedInc    0.526011\n",
            "5    AveOccup    0.138220\n",
            "7   Longitude    0.086124\n",
            "6    Latitude    0.086086\n",
            "1    HouseAge    0.054654\n",
            "2    AveRooms    0.047188\n",
            "4  Population    0.031722\n",
            "3   AveBedrms    0.029995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.30/  Train an ensemble model using both Bagging and Random Forest and compare accuracy ?"
      ],
      "metadata": {
        "id": "PJSVZ88aM8ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=dt,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "y_pred_bag = bagging.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Bagging Classifier Accuracy:\", acc_bag)\n",
        "print(\"Random Forest Classifier Accuracy:\", acc_rf)\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "if acc_rf > acc_bag:\n",
        "    print(\"Random Forest performed better.\")\n",
        "else:\n",
        "    print(\"Bagging performed better.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ0uiF7lNyTH",
        "outputId": "56c01afc-c825-476a-a5c0-97e2a068b1d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9590643274853801\n",
            "Random Forest Classifier Accuracy: 0.9707602339181286\n",
            "\n",
            "Comparison:\n",
            "Random Forest performed better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.31/Train a Random Forest Classifier and tune hyperparameters using GridSearchCV ?"
      ],
      "metadata": {
        "id": "ZKxRQLY4YYeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Test Accuracy after tuning:\", accuracy)"
      ],
      "metadata": {
        "id": "KgqhYFkEYlj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e120796d-e6d4-43e2-f08d-9a1d69407b7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Test Accuracy after tuning: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.32/ Train a Bagging Regressor with different numbers of base estimators and compare performance ?"
      ],
      "metadata": {
        "id": "H-XB4hLdGhQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "estimators = [10, 50, 100, 200]\n",
        "\n",
        "for n in estimators:\n",
        "    bagging = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(random_state=42),n_estimators=n,random_state=42)\n",
        "    bagging.fit(X_train, y_train)\n",
        "    y_pred = bagging.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Number of Estimators: {n}, MSE: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XLuJXWSGqy_",
        "outputId": "a14e54d3-92ee-4a5b-b1a9-ef89cb3382ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Estimators: 10, MSE: 0.2862\n",
            "Number of Estimators: 50, MSE: 0.2579\n",
            "Number of Estimators: 100, MSE: 0.2568\n",
            "Number of Estimators: 200, MSE: 0.2542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.33/Train a Random Forest Classifier and analyze misclassified samples ?"
      ],
      "metadata": {
        "id": "8n_0d8D8Hh-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "misclassified_idx = y_test != y_pred\n",
        "misclassified_samples = pd.DataFrame(\n",
        "    X_test[misclassified_idx],\n",
        "    columns=data.feature_names\n",
        ")\n",
        "misclassified_samples[\"Actual\"] = y_test[misclassified_idx]\n",
        "misclassified_samples[\"Predicted\"] = y_pred[misclassified_idx]\n",
        "print(\"\\nNumber of Misclassified Samples:\", misclassified_samples.shape[0])\n",
        "print(\"\\nMisclassified Samples (first 5 rows):\")\n",
        "print(misclassified_samples.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyoqrhhhIAzc",
        "outputId": "7fb10498-729b-4f09-e31a-646b944c3044"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9707602339181286\n",
            "\n",
            "Number of Misclassified Samples: 5\n",
            "\n",
            "Misclassified Samples (first 5 rows):\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        13.34         15.86           86.49      520.0          0.10780   \n",
            "1        13.80         15.79           90.43      584.1          0.10070   \n",
            "2        13.96         17.05           91.43      602.4          0.10960   \n",
            "3        14.48         21.46           94.25      648.2          0.09444   \n",
            "4        15.13         29.81           96.71      719.5          0.08320   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.15350         0.11690              0.06987         0.1942   \n",
            "1           0.12800         0.07789              0.05069         0.1662   \n",
            "2           0.12790         0.09789              0.05246         0.1908   \n",
            "3           0.09947         0.12040              0.04938         0.2075   \n",
            "4           0.04605         0.04686              0.02739         0.1852   \n",
            "\n",
            "   mean fractal dimension  ...  worst perimeter  worst area  worst smoothness  \\\n",
            "0                 0.06902  ...            96.66       614.9            0.1536   \n",
            "1                 0.06566  ...           110.30       812.4            0.1411   \n",
            "2                 0.06130  ...           108.10       826.0            0.1512   \n",
            "3                 0.05636  ...           108.40       808.9            0.1306   \n",
            "4                 0.05294  ...           110.10       931.4            0.1148   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0            0.47910           0.4858               0.17080          0.3527   \n",
            "1            0.35420           0.2779               0.13830          0.2589   \n",
            "2            0.32620           0.3209               0.13740          0.3068   \n",
            "3            0.19760           0.3349               0.12250          0.3020   \n",
            "4            0.09866           0.1547               0.06575          0.3233   \n",
            "\n",
            "   worst fractal dimension  Actual  Predicted  \n",
            "0                  0.10160       1          0  \n",
            "1                  0.10300       0          1  \n",
            "2                  0.07957       0          1  \n",
            "3                  0.06846       0          1  \n",
            "4                  0.06165       0          1  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.34/ Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier ?"
      ],
      "metadata": {
        "id": "QuVuSEr7IgyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "y_pred_bag = bagging.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", acc_dt)\n",
        "print(\"Bagging Classifier Accuracy:\", acc_bag)\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "if acc_bag > acc_dt:\n",
        "    print(\"Bagging Classifier performed better.\")\n",
        "else:\n",
        "    print(\"Decision Tree performed better.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5E-IvtdIgeX",
        "outputId": "c7d3ac25-f5b6-4f59-cdb9-4f01bc00bd4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9415204678362573\n",
            "Bagging Classifier Accuracy: 0.9590643274853801\n",
            "\n",
            "Comparison:\n",
            "Bagging Classifier performed better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.35/ Train a Random Forest Classifier and visualize the confusion matrix ?"
      ],
      "metadata": {
        "id": "QYfp3vyPKBiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=data.target_names)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "i7oyvjMQKQ4T",
        "outputId": "5b41ec36-4e79-4f99-d80d-9ee8db4c1112"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9707602339181286\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q.36/Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy ?"
      ],
      "metadata": {
        "id": "pWqApXotLLH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "base_learners = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=42)),\n",
        "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True, random_state=42))),\n",
        "    ('lr_base', LogisticRegression())\n",
        "]\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5\n",
        ")\n",
        "stack_clf.fit(X_train, y_train)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in base_learners:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "stack_pred = stack_clf.predict(X_test)\n",
        "results['Stacked Model'] = accuracy_score(y_test, stack_pred)\n",
        "\n",
        "print(\"--- Accuracy Comparison ---\")\n",
        "for model_name, score in results.items():\n",
        "    print(f\"{model_name:15}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlx8EYkkM-4F",
        "outputId": "22555a41-dfa8-41c7-d648-02bb5b6de341"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Accuracy Comparison ---\n",
            "dt             : 0.8750\n",
            "svm            : 0.8450\n",
            "lr_base        : 0.8550\n",
            "Stacked Model  : 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.37/ Train a Random Forest Classifier and print the top 5 most important features ?"
      ],
      "metadata": {
        "id": "ZXSH-M3SN6ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": importances\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(feature_importance_df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv6WKCbSOF9s",
        "outputId": "7a282e06-ef22-452c-85d7-04d188eba94d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "                 Feature  Importance\n",
            "7    mean concave points    0.141934\n",
            "27  worst concave points    0.127136\n",
            "23            worst area    0.118217\n",
            "6         mean concavity    0.080557\n",
            "20          worst radius    0.077975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.38/ Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score ?"
      ],
      "metadata": {
        "id": "feafD9cdQF9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=dt,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBvFY1QYQNrR",
        "outputId": "370eed30-eea7-437d-82e7-9318c3d11ca0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9583333333333334\n",
            "Recall: 0.971830985915493\n",
            "F1-score: 0.965034965034965\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        43\n",
            "           1       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.39/ Train a Random Forest Classifier and analyze the effect of max_depth on accuracy ?"
      ],
      "metadata": {
        "id": "kZmdxxG5REq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "depths = [None, 2, 4, 6, 8, 10]\n",
        "accuracies = []\n",
        "for d in depths:\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=d,\n",
        "        random_state=42\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "for d, acc in zip(depths, accuracies):\n",
        "    print(f\"max_depth = {d} --> Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_b7UW8TRLz6",
        "outputId": "28f506e2-7b08-4f6d-a467-62a820ad586c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth = None --> Accuracy = 0.9649\n",
            "max_depth = 2 --> Accuracy = 0.9649\n",
            "max_depth = 4 --> Accuracy = 0.9649\n",
            "max_depth = 6 --> Accuracy = 0.9649\n",
            "max_depth = 8 --> Accuracy = 0.9649\n",
            "max_depth = 10 --> Accuracy = 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.40/ Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
        "performance ?"
      ],
      "metadata": {
        "id": "OUCLFkubR0Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "bag_dt = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bag_dt.fit(X_train, y_train)\n",
        "pred_dt = bag_dt.predict(X_test)\n",
        "\n",
        "bag_knn = BaggingRegressor(\n",
        "    estimator=KNeighborsRegressor(n_neighbors=5),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_knn.fit(X_train, y_train)\n",
        "pred_knn = bag_knn.predict(X_test)\n",
        "\n",
        "print(\"Bagging + Decision Tree\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_dt))\n",
        "print(\"R2 Score:\", r2_score(y_test, pred_dt))\n",
        "print(\"\\nBagging + KNN\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_knn))\n",
        "print(\"R2 Score:\", r2_score(y_test, pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-impjoSATQ",
        "outputId": "147c0cde-3a0f-4215-dd09-eaa5a7aa743c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging + Decision Tree\n",
            "MSE: 0.25592438609899626\n",
            "R2 Score: 0.8046988456668309\n",
            "\n",
            "Bagging + KNN\n",
            "MSE: 1.0762752887085227\n",
            "R2 Score: 0.1786722263202739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.41/ Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score ?"
      ],
      "metadata": {
        "id": "6DKwCvdcPS8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxrUFr3PTPK",
        "outputId": "5931230b-049e-4378-d203-c2015004f950"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9952505732066819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.42/ Train a Bagging Classifier and evaluate its performance using cross-validatio ?"
      ],
      "metadata": {
        "id": "yWIgO9fsQCLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=dt, n_estimators=100, random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    bagging_model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2ecI15lPq3n",
        "outputId": "1304bcb2-6d3f-4c9a-9f58-8e3bc962323d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.89473684 0.93859649 0.99122807 0.96491228 1.        ]\n",
            "Mean CV Accuracy: 0.9578947368421054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.43/ Train a Random Forest Classifier and plot the Precision-Recall curv ?"
      ],
      "metadata": {
        "id": "6dMMzot8QyNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_scores = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(f\"Precision-Recall Curve (AP = {avg_precision:.2f})\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "pl3BpuwuQ84B",
        "outputId": "83551881-e332-4992-edcc-aca18720c66f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.44/ Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy ?"
      ],
      "metadata": {
        "id": "xm8dKRcWR4BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "lr = LogisticRegression(max_iter=5000)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf.predict(X_test)\n",
        "lr_pred = lr.predict(X_test)\n",
        "\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "lr_acc = accuracy_score(y_test, lr_pred)\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf),\n",
        "        ('lr', lr)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=5000)\n",
        ")\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "stack_pred = stack_model.predict(X_test)\n",
        "stack_acc = accuracy_score(y_test, stack_pred)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "print(\"Logistic Regression Accuracy:\", lr_acc)\n",
        "print(\"Stacking Classifier Accuracy:\", stack_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCY-SSAsR3v8",
        "outputId": "a56dd880-8665-4082-c5fc-7a7a64f9032d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9707602339181286\n",
            "Logistic Regression Accuracy: 0.9766081871345029\n",
            "Stacking Classifier Accuracy: 0.9707602339181286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.45/ Train a Bagging Regressor with different levels of bootstrap samples and compare performance ?"
      ],
      "metadata": {
        "id": "gOLTPgInTFTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "sample_sizes = [0.5, 0.7, 1.0]\n",
        "for size in sample_sizes:\n",
        "    bagging_reg = BaggingRegressor(estimator=dt,n_estimators=100,max_samples=size,\n",
        "        bootstrap=True,random_state=42\n",
        "    )\n",
        "\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bootstrap sample size = {size} → MSE = {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vINwCxlNTNzM",
        "outputId": "b34b521d-972b-4b5f-d85d-f874a98b3991"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap sample size = 0.5 → MSE = 0.2626\n",
            "Bootstrap sample size = 0.7 → MSE = 0.2585\n",
            "Bootstrap sample size = 1.0 → MSE = 0.2568\n"
          ]
        }
      ]
    }
  ]
}